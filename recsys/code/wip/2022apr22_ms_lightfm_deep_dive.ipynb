{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alboard/kaggle/blob/main/recsys/code/wip/2022apr22_ms_lightfm_deep_dive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jf_RYVKSMH1"
      },
      "source": [
        "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
        "\n",
        "<i>Licensed under the MIT License.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlLcaz6uqVSF"
      },
      "source": [
        "## Building a Movie Hybrid Based Recommendation System\n",
        "https://github.com/microsoft/recommenders/blob/main/examples/02_model_hybrid/lightfm_deep_dive.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eIRiP5nrvHS"
      },
      "source": [
        "This will recomend similar films to similar users - this film as that user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfEfIZ_grKt_"
      },
      "source": [
        "Different format data set - could munge to same  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0uUHmdwSUc8",
        "outputId": "538bad0c-c317-4feb-834a-32dfe0c752ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n40X2jL8Sg7U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lAHbu6MGSsqf",
        "outputId": "5a1e258e-e92f-43d4-e374-2e59d53b3645"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# !mv \\'/content/drive/MyDrive/Colab Notebooks/data/kaggle.json\\' /root/.kaggle\\n!cd ~\\n!pwd\\n!ls\\n!cd \\'/content/drive/MyDrive/_data/kaggle\\'\\nos.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/drive/MyDrive/_data/\"\\n!kaggle datasets download -d rounakbanik/the-movies-dataset -p \\'/content/drive/MyDrive/_data/kaggle\\'\\nos.chdir(\\'/content/drive/MyDrive/_data/kaggle\\')\\nfor file in os.listdir():\\n    zip_ref = zipfile.ZipFile(file, \\'r\\')\\n    zip_ref.extractall()\\n    zip_ref.close()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "# !mv '/content/drive/MyDrive/Colab Notebooks/data/kaggle.json' /root/.kaggle\n",
        "!cd ~\n",
        "!pwd\n",
        "!ls\n",
        "!cd '/content/drive/MyDrive/_data/kaggle'\n",
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/drive/MyDrive/_data/\"\n",
        "!kaggle datasets download -d rounakbanik/the-movies-dataset -p '/content/drive/MyDrive/_data/kaggle'\n",
        "os.chdir('/content/drive/MyDrive/_data/kaggle')\n",
        "for file in os.listdir():\n",
        "    zip_ref = zipfile.ZipFile(file, 'r')\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZkh41bfnWhe",
        "outputId": "a6cd17f4-d7cf-437b-84cb-c466bc5ffd5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "credits.csv   links.csv        movies_metadata.csv  ratings_small.csv\n",
            "keywords.csv  links_small.csv  ratings.csv\t    the-movies-dataset.zip\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/_data/kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci6sqQhrSMH5"
      },
      "source": [
        "# LightFM -  hybrid matrix factorisation on MovieLens (Python, CPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMjJ0sl2SMH5"
      },
      "source": [
        "This notebook explains the concept of a hybrid matrix factorisation based model for recommendation, it also outlines the steps to construct a pure matrix factorisation and a hybrid models using the [LightFM](https://github.com/lyst/lightfm) package. It also demonstrates how to extract both user and item affinity from a fitted hybrid model.\n",
        "\n",
        "## 1. Hybrid matrix factorisation model\n",
        "\n",
        "### 1.1 Background\n",
        "\n",
        "In general, most recommendation models can be divided into two categories:\n",
        "- Content based model,\n",
        "- Collaborative filtering model.\n",
        "\n",
        "The content-based model recommends based on similarity of the items and/or users using their description/metadata/profile. On the other hand, collaborative filtering model (discussion is limited to matrix factorisation approach in this notebook) computes the latent factors of the users and items. It works based on the assumption that if a group of people expressed similar opinions on an item, these peole would tend to have similar opinions on other items. For further background and detailed explanation between these two approaches, the reader can refer to machine learning literatures [3, 4].\n",
        "\n",
        "The choice between the two models is largely based on the data availability. For example, the collaborative filtering model is usually adopted and effective when sufficient ratings/feedbacks have been recorded for a group of users and items.\n",
        "\n",
        "However, if there is a lack of ratings, content based model can be used provided that the metadata of the users and items are available. This is also the common approach to address the cold-start issues, where there are insufficient historical collaborative interactions available to model new users and/or items.\n",
        "\n",
        "<!-- In addition, most collaborative filtering models only consume explicit ratings e.g. movie \n",
        "\n",
        "**NOTE** add stuff about implicit and explicit ratings -->\n",
        "\n",
        "### 1.2 Hybrid matrix factorisation algorithm\n",
        "\n",
        "In view of the above problems, there have been a number of proposals to address the cold-start issues by combining both content-based and collaborative filtering approaches. The hybrid matrix factorisation model is among one of the solutions proposed [1].  \n",
        "\n",
        "In general, most hybrid approaches proposed different ways of assessing and/or combining the feature data in conjunction with the collaborative information.\n",
        "\n",
        "### 1.3 LightFM package \n",
        "\n",
        "LightFM is a Python implementation of a hybrid recommendation algorithms for both implicit and explicit feedbacks [1].\n",
        "\n",
        "It is a hybrid content-collaborative model which represents users and items as linear combinations of their content features’ latent factors. The model learns **embeddings or latent representations of the users and items in such a way that it encodes user preferences over items**. These representations produce scores for every item for a given user; items scored highly are more likely to be interesting to the user.\n",
        "\n",
        "The user and item embeddings are estimated for every feature, and these features are then added together to be the final representations for users and items. \n",
        "\n",
        "For example, for user i, the model retrieves the i-th row of the feature matrix to find the features with non-zero weights. The embeddings for these features will then be added together to become the user representation e.g. if user 10 has weight 1 in the 5th column of the user feature matrix, and weight 3 in the 20th column, the user 10’s representation is the sum of embedding for the 5th and the 20th features multiplying their corresponding weights. The representation for each items is computed in the same approach. \n",
        "\n",
        "#### 1.3.1 Modelling approach\n",
        "\n",
        "Let $U$ be the set of users and $I$ be the set of items, and each user can be described by a set of user features $f_{u} \\subset F^{U}$ whilst each items can be described by item features $f_{i} \\subset F^{I}$. Both $F^{U}$ and $F^{I}$ are all the features which fully describe all users and items. \n",
        "\n",
        "The LightFM model operates based binary feedbacks, the ratings will be normalised into two groups. The user-item interaction pairs $(u,i) \\in U\\times I$ are the union of positive (favourable reviews) $S^+$ and negative interactions (negative reviews) $S^-$ for explicit ratings. For implicit feedbacks, these can be the observed and not observed interactions respectively.\n",
        "\n",
        "For each user and item feature, their embeddings are $e_{f}^{U}$ and $e_{f}^{I}$ respectively. Furthermore, each feature is also has a scalar bias term ($b_U^f$ for user and $b_I^f$ for item features). The embedding (latent representation) of user $u$ and item $i$ are the sum of its respective features’ latent vectors:\n",
        "\n",
        "$$ \n",
        "q_{u} = \\sum_{j \\in f_{u}} e_{j}^{U}\n",
        "$$\n",
        "\n",
        "$$\n",
        "p_{i} = \\sum_{j \\in f_{i}} e_{j}^{I}\n",
        "$$\n",
        "\n",
        "Similarly the biases for user $u$ and item $i$ are the sum of its respective bias vectors. These variables capture the variation in behaviour across users and items:\n",
        "\n",
        "$$\n",
        "b_{u} = \\sum_{j \\in f_{u}} b_{j}^{U}\n",
        "$$\n",
        "\n",
        "$$\n",
        "b_{i} = \\sum_{j \\in f_{i}} b_{j}^{I}\n",
        "$$\n",
        "\n",
        "In LightFM, the representation for each user/item is a linear weighted sum of its feature vectors.\n",
        "\n",
        "The prediction for user $u$ and item $i$ can be modelled as sigmoid of the dot product of user and item vectors, adjusted by its feature biases as follows:\n",
        "\n",
        "$$\n",
        "\\hat{r}_{ui} = \\sigma (q_{u} \\cdot p_{i} + b_{u} + b_{i})\n",
        "$$\n",
        "\n",
        "As the LightFM is constructed to predict binary outcomes e.g. $S^+$ and $S^-$, the function $\\sigma()$ is based on the [sigmoid function](https://mathworld.wolfram.com/SigmoidFunction.html). \n",
        "\n",
        "The LightFM algorithm estimates interaction latent vectors and bias for features. For model fitting, the cost function of the model consists of maximising the likelihood of data conditional on the parameters described above using stochastic gradient descent. The likelihood can be expressed as follows:\n",
        "\n",
        "$$\n",
        "L = \\prod_{(u,i) \\in S+}\\hat{r}_{ui} \\times \\prod_{(u,i) \\in S-}1 - \\hat{r}_{ui}\n",
        "$$\n",
        "\n",
        "Note that if the feature latent vectors are not available, the algorithm will behaves like a [logistic matrix factorisation model](http://stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pnJRfusSMH8"
      },
      "source": [
        "## 2. Movie recommender with LightFM using only explicit feedbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgGVBtooSMH8"
      },
      "source": [
        "### 2.1 Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zw4aNRjTI3g",
        "outputId": "e7a04a31-6ed5-4fcf-c22d-256f9bf00648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.24.2)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.24.2\n",
            "    Uninstalling scikit-learn-0.24.2:\n",
            "      Successfully uninstalled scikit-learn-0.24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "recommenders 0.6.0 requires scikit-learn<1,>=0.22.1, but you have scikit-learn 1.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-1.0.2\n",
            "Requirement already satisfied: lightfm in /usr/local/lib/python3.7/dist-packages (1.16)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.1.0)\n",
            "Collecting recommenders\n",
            "  Using cached recommenders-0.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-surprise<=1.1.1,>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.1.1)\n",
            "Requirement already satisfied: seaborn<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (0.11.2)\n",
            "Requirement already satisfied: bottleneck<2,>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.3.4)\n",
            "Requirement already satisfied: category-encoders<2,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.3.0)\n",
            "Requirement already satisfied: matplotlib<4,>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from recommenders) (3.2.2)\n",
            "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.3.3)\n",
            "Requirement already satisfied: pydocumentdb>=2.3.3<3 in /usr/local/lib/python3.7/dist-packages (from recommenders) (2.3.5)\n",
            "Requirement already satisfied: memory-profiler<1,>=0.54.0 in /usr/local/lib/python3.7/dist-packages (from recommenders) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.21.6)\n",
            "Requirement already satisfied: cornac<2,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.14.2)\n",
            "Requirement already satisfied: pyyaml<6,>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (5.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from recommenders) (2.23.0)\n",
            "Requirement already satisfied: lightfm<2,>=1.15 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.16)\n",
            "Requirement already satisfied: pandas<2,>1.0.3 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.3.5)\n",
            "Requirement already satisfied: pymanopt<1,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from recommenders) (0.2.5)\n",
            "Collecting scikit-learn<1,>=0.22.1\n",
            "  Using cached scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "Requirement already satisfied: nltk<4,>=3.4 in /usr/local/lib/python3.7/dist-packages (from recommenders) (3.7)\n",
            "Requirement already satisfied: tqdm<5,>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (4.64.0)\n",
            "Requirement already satisfied: lightgbm<3,>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (2.2.3)\n",
            "Requirement already satisfied: numba<1,>=0.38.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (0.51.2)\n",
            "Requirement already satisfied: jinja2<3,>=2 in /usr/local/lib/python3.7/dist-packages (from recommenders) (2.11.3)\n",
            "Requirement already satisfied: transformers<5,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from recommenders) (4.18.0)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders<2,>=1.3.0->recommenders) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders<2,>=1.3.0->recommenders) (0.5.2)\n",
            "Requirement already satisfied: powerlaw in /usr/local/lib/python3.7/dist-packages (from cornac<2,>=1.1.2->recommenders) (1.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3,>=2->recommenders) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<4,>=2.2.2->recommenders) (4.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler<1,>=0.54.0->recommenders) (5.4.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->recommenders) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->recommenders) (2022.3.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->recommenders) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<1,>=0.38.1->recommenders) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba<1,>=0.38.1->recommenders) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>1.0.3->recommenders) (2022.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->category-encoders<2,>=1.3.0->recommenders) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1,>=0.22.1->recommenders) (3.1.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (0.12.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (0.0.49)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (4.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (3.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5,>=2.5.0->recommenders) (3.8.0)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac<2,>=1.1.2->recommenders) (1.2.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.24.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade scikit-learn\n",
        "!pip install lightfm\n",
        "!pip install git+https://github.com/microsoft/recommenders@98d661edc6a9965c7f42b76dc5317af3ae74d5e0#egg=recommenders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMHl9dEGSMH9",
        "outputId": "6f7e9aff-32ba-4e27-9d3b-0b739cebd2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System version: 3.7.13 (default, Mar 16 2022, 17:37:17) \n",
            "[GCC 7.5.0]\n",
            "LightFM version: 1.16\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import lightfm\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm import cross_validation\n",
        "\n",
        "# Import LightFM's evaluation metrics\n",
        "from lightfm.evaluation import precision_at_k as lightfm_prec_at_k\n",
        "from lightfm.evaluation import recall_at_k as lightfm_recall_at_k\n",
        "\n",
        "# Import repo's evaluation metrics\n",
        "from recommenders.evaluation.python_evaluation import (\n",
        "    precision_at_k, recall_at_k)\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.datasets import movielens\n",
        "from recommenders.models.lightfm.lightfm_utils import (\n",
        "    track_model_metrics, prepare_test_df, prepare_all_predictions,\n",
        "    compare_metric, similar_users, similar_items)\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"LightFM version: {}\".format(lightfm.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97syhQaTSMH_"
      },
      "source": [
        "### 2.2 Defining variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0131k6npSMH_"
      },
      "outputs": [],
      "source": [
        "# Select MovieLens data size\n",
        "MOVIELENS_DATA_SIZE = '100k'\n",
        "\n",
        "# default number of recommendations\n",
        "K = 10\n",
        "# percentage of data used for testing\n",
        "TEST_PERCENTAGE = 0.25\n",
        "# model learning rate\n",
        "LEARNING_RATE = 0.25\n",
        "# no of latent factors\n",
        "NO_COMPONENTS = 20\n",
        "# no of epochs to fit model\n",
        "NO_EPOCHS = 20\n",
        "# no of threads to fit model\n",
        "NO_THREADS = 32\n",
        "# regularisation for both user and item features\n",
        "ITEM_ALPHA=1e-6\n",
        "USER_ALPHA=1e-6\n",
        "\n",
        "# seed for pseudonumber generations\n",
        "SEEDNO = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e6c8T3bFXqPE"
      },
      "outputs": [],
      "source": [
        "df_credits = pd.read_csv('/content/drive/MyDrive/_data/kaggle/credits.csv', low_memory=False)\n",
        "df_keywords = pd.read_csv('/content/drive/MyDrive/_data/kaggle/keywords.csv', low_memory=False)\n",
        "df_links = pd.read_csv('/content/drive/MyDrive/_data/kaggle/links.csv', low_memory=False)\n",
        "df_links_small = pd.read_csv('/content/drive/MyDrive/_data/kaggle/links_small.csv', low_memory=False)\n",
        "df_movies_metadata = pd.read_csv('/content/drive/MyDrive/_data/kaggle/movies_metadata.csv', low_memory=False)\n",
        "df_ratings = pd.read_csv('/content/drive/MyDrive/_data/kaggle/ratings.csv', low_memory=False)\n",
        "df_ratings_small = pd.read_csv('/content/drive/MyDrive/_data/kaggle/ratings_small.csv', low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qufcKM14d2MG",
        "outputId": "240679a4-e3c8-4a6e-b09d-45b5b81de3dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        adult                              belongs_to_collection    budget  \\\n",
              "0      False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
              "1      False                                                NaN  65000000   \n",
              "2      False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
              "3      False                                                NaN  16000000   \n",
              "4      False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
              "...      ...                                                ...       ...   \n",
              "45461  False                                                NaN         0   \n",
              "45462  False                                                NaN         0   \n",
              "45463  False                                                NaN         0   \n",
              "45464  False                                                NaN         0   \n",
              "45465  False                                                NaN         0   \n",
              "\n",
              "                                                  genres  \\\n",
              "0      [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
              "1      [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
              "2      [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
              "3      [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
              "4                         [{'id': 35, 'name': 'Comedy'}]   \n",
              "...                                                  ...   \n",
              "45461  [{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...   \n",
              "45462                      [{'id': 18, 'name': 'Drama'}]   \n",
              "45463  [{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...   \n",
              "45464                                                 []   \n",
              "45465                                                 []   \n",
              "\n",
              "                                   homepage      id    imdb_id  \\\n",
              "0      http://toystory.disney.com/toy-story     862  tt0114709   \n",
              "1                                       NaN    8844  tt0113497   \n",
              "2                                       NaN   15602  tt0113228   \n",
              "3                                       NaN   31357  tt0114885   \n",
              "4                                       NaN   11862  tt0113041   \n",
              "...                                     ...     ...        ...   \n",
              "45461  http://www.imdb.com/title/tt6209470/  439050  tt6209470   \n",
              "45462                                   NaN  111109  tt2028550   \n",
              "45463                                   NaN   67758  tt0303758   \n",
              "45464                                   NaN  227506  tt0008536   \n",
              "45465                                   NaN  461257  tt6980792   \n",
              "\n",
              "      original_language               original_title  \\\n",
              "0                    en                    Toy Story   \n",
              "1                    en                      Jumanji   \n",
              "2                    en             Grumpier Old Men   \n",
              "3                    en            Waiting to Exhale   \n",
              "4                    en  Father of the Bride Part II   \n",
              "...                 ...                          ...   \n",
              "45461                fa                      رگ خواب   \n",
              "45462                tl          Siglo ng Pagluluwal   \n",
              "45463                en                     Betrayal   \n",
              "45464                en          Satana likuyushchiy   \n",
              "45465                en                     Queerama   \n",
              "\n",
              "                                                overview  ... release_date  \\\n",
              "0      Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
              "1      When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
              "2      A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
              "3      Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
              "4      Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
              "...                                                  ...  ...          ...   \n",
              "45461        Rising and falling between a man and woman.  ...          NaN   \n",
              "45462  An artist struggles to finish his work while a...  ...   2011-11-17   \n",
              "45463  When one of her hits goes wrong, a professiona...  ...   2003-08-01   \n",
              "45464  In a small town live two brothers, one a minis...  ...   1917-10-21   \n",
              "45465  50 years after decriminalisation of homosexual...  ...   2017-06-09   \n",
              "\n",
              "           revenue runtime                                   spoken_languages  \\\n",
              "0      373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "1      262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
              "2              0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "3       81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "4       76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "...            ...     ...                                                ...   \n",
              "45461          0.0    90.0             [{'iso_639_1': 'fa', 'name': 'فارسی'}]   \n",
              "45462          0.0   360.0                  [{'iso_639_1': 'tl', 'name': ''}]   \n",
              "45463          0.0    90.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "45464          0.0    87.0                                                 []   \n",
              "45465          0.0    75.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "\n",
              "         status                                            tagline  \\\n",
              "0      Released                                                NaN   \n",
              "1      Released          Roll the dice and unleash the excitement!   \n",
              "2      Released  Still Yelling. Still Fighting. Still Ready for...   \n",
              "3      Released  Friends are the people who let you be yourself...   \n",
              "4      Released  Just When His World Is Back To Normal... He's ...   \n",
              "...         ...                                                ...   \n",
              "45461  Released         Rising and falling between a man and woman   \n",
              "45462  Released                                                NaN   \n",
              "45463  Released                             A deadly game of wits.   \n",
              "45464  Released                                                NaN   \n",
              "45465  Released                                                NaN   \n",
              "\n",
              "                             title  video vote_average vote_count  \n",
              "0                        Toy Story  False          7.7     5415.0  \n",
              "1                          Jumanji  False          6.9     2413.0  \n",
              "2                 Grumpier Old Men  False          6.5       92.0  \n",
              "3                Waiting to Exhale  False          6.1       34.0  \n",
              "4      Father of the Bride Part II  False          5.7      173.0  \n",
              "...                            ...    ...          ...        ...  \n",
              "45461                       Subdue  False          4.0        1.0  \n",
              "45462          Century of Birthing  False          9.0        3.0  \n",
              "45463                     Betrayal  False          3.8        6.0  \n",
              "45464             Satan Triumphant  False          0.0        0.0  \n",
              "45465                     Queerama  False          0.0        0.0  \n",
              "\n",
              "[45466 rows x 24 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# df_ratings = pd.read_csv('/content/drive/MyDrive/_data/kaggle/ratings.csv', low_memory=False)\n",
        "df_movies_metadata.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YV2TBbrfeQQi"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ZOqfJMqSVX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wf7B5zSWbihI"
      },
      "outputs": [],
      "source": [
        "df_ratings['movieId'] = pd.to_numeric(df_ratings['movieId'], errors='coerce')\n",
        "df_movies_metadata['id'] = pd.to_numeric(df_movies_metadata['id'], errors='coerce')\n",
        "df_ratings.rename(columns = {'movieId':'id'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BU7lQwSbBC7_"
      },
      "outputs": [],
      "source": [
        "df_ratings_small['movieId'] = pd.to_numeric(df_ratings_small['movieId'], errors='coerce')\n",
        "df_movies_metadata['id'] = pd.to_numeric(df_movies_metadata['id'], errors='coerce')\n",
        "df_ratings_small.rename(columns = {'movieId':'id'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dTECranFYSo1"
      },
      "outputs": [],
      "source": [
        "data = pd.merge(df_ratings_small, df_movies_metadata, on = 'id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSOk7KIyqRNO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "kQI4HFTySMIA",
        "outputId": "ad7a49d5-6fb3-489c-97e3-a28f41155f87",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       userId    id  rating   timestamp  adult  \\\n",
              "20513     472  4896     3.0  1006928698  False   \n",
              "28214     545  1956     5.0   938566176  False   \n",
              "43370     311  4339     3.5  1115160571  False   \n",
              "35721     666   236     3.0   838921142  False   \n",
              "42078     240  1885     4.5  1098943951  False   \n",
              "\n",
              "                                   belongs_to_collection   budget  \\\n",
              "20513                                                NaN    40000   \n",
              "28214                                                NaN  3500000   \n",
              "43370                                                NaN        0   \n",
              "35721                                                NaN  3000000   \n",
              "42078  {'id': 8580, 'name': 'The Karate Kid Collectio...  8000000   \n",
              "\n",
              "                                                  genres  \\\n",
              "20513  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
              "28214  [{'id': 9648, 'name': 'Mystery'}, {'id': 18, '...   \n",
              "43370  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
              "35721  [{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...   \n",
              "42078                      [{'id': 18, 'name': 'Drama'}]   \n",
              "\n",
              "                              homepage    imdb_id  ... release_date  \\\n",
              "20513  http://www.mux-braucht-dich.de/  tt0396746  ...   2004-01-28   \n",
              "28214                              NaN  tt0302674  ...   2002-01-12   \n",
              "43370                              NaN  tt0100557  ...   1990-02-15   \n",
              "35721                              NaN  tt0110598  ...   1994-09-29   \n",
              "42078                              NaN  tt0087538  ...   1984-06-22   \n",
              "\n",
              "          revenue runtime                                   spoken_languages  \\\n",
              "20513         0.0    90.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
              "28214         0.0   103.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "43370         0.0    92.0           [{'iso_639_1': 'de', 'name': 'Deutsch'}]   \n",
              "35721  15119639.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "42078  90815558.0   126.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "\n",
              "         status                                            tagline  \\\n",
              "20513  Released                                                NaN   \n",
              "28214  Released                                                NaN   \n",
              "43370  Released                                                NaN   \n",
              "35721  Released                       Success is the best revenge.   \n",
              "42078  Released  Only the 'Old One' could teach him the secrets...   \n",
              "\n",
              "                  title  video  vote_average  vote_count  \n",
              "20513  Muxmäuschenstill  False           7.1         7.0  \n",
              "28214             Gerry  False           6.1        69.0  \n",
              "43370    The Nasty Girl  False           5.9         5.0  \n",
              "35721  Muriel's Wedding  False           6.9       104.0  \n",
              "42078    The Karate Kid  False           6.9       913.0  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a54ca132-a56d-4bfe-9ab7-83f2ec712d1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>adult</th>\n",
              "      <th>belongs_to_collection</th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>...</th>\n",
              "      <th>release_date</th>\n",
              "      <th>revenue</th>\n",
              "      <th>runtime</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>status</th>\n",
              "      <th>tagline</th>\n",
              "      <th>title</th>\n",
              "      <th>video</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20513</th>\n",
              "      <td>472</td>\n",
              "      <td>4896</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1006928698</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40000</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
              "      <td>http://www.mux-braucht-dich.de/</td>\n",
              "      <td>tt0396746</td>\n",
              "      <td>...</td>\n",
              "      <td>2004-01-28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Muxmäuschenstill</td>\n",
              "      <td>False</td>\n",
              "      <td>7.1</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28214</th>\n",
              "      <td>545</td>\n",
              "      <td>1956</td>\n",
              "      <td>5.0</td>\n",
              "      <td>938566176</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3500000</td>\n",
              "      <td>[{'id': 9648, 'name': 'Mystery'}, {'id': 18, '...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt0302674</td>\n",
              "      <td>...</td>\n",
              "      <td>2002-01-12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gerry</td>\n",
              "      <td>False</td>\n",
              "      <td>6.1</td>\n",
              "      <td>69.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43370</th>\n",
              "      <td>311</td>\n",
              "      <td>4339</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1115160571</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt0100557</td>\n",
              "      <td>...</td>\n",
              "      <td>1990-02-15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>[{'iso_639_1': 'de', 'name': 'Deutsch'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Nasty Girl</td>\n",
              "      <td>False</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35721</th>\n",
              "      <td>666</td>\n",
              "      <td>236</td>\n",
              "      <td>3.0</td>\n",
              "      <td>838921142</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3000000</td>\n",
              "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 35, 'name...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt0110598</td>\n",
              "      <td>...</td>\n",
              "      <td>1994-09-29</td>\n",
              "      <td>15119639.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>Success is the best revenge.</td>\n",
              "      <td>Muriel's Wedding</td>\n",
              "      <td>False</td>\n",
              "      <td>6.9</td>\n",
              "      <td>104.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42078</th>\n",
              "      <td>240</td>\n",
              "      <td>1885</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1098943951</td>\n",
              "      <td>False</td>\n",
              "      <td>{'id': 8580, 'name': 'The Karate Kid Collectio...</td>\n",
              "      <td>8000000</td>\n",
              "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt0087538</td>\n",
              "      <td>...</td>\n",
              "      <td>1984-06-22</td>\n",
              "      <td>90815558.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>Only the 'Old One' could teach him the secrets...</td>\n",
              "      <td>The Karate Kid</td>\n",
              "      <td>False</td>\n",
              "      <td>6.9</td>\n",
              "      <td>913.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a54ca132-a56d-4bfe-9ab7-83f2ec712d1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a54ca132-a56d-4bfe-9ab7-83f2ec712d1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a54ca132-a56d-4bfe-9ab7-83f2ec712d1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "'''\n",
        "data = movielens.load_pandas_df(        \n",
        "    size=MOVIELENS_DATA_SIZE,\n",
        "    genres_col='genre',\n",
        "    header=[\"userID\", \"itemID\", \"rating\"]\n",
        ")\n",
        "'''\n",
        "# quick look at the data\n",
        "data.sample(5)\n",
        "# type(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8EXr8HSMIA"
      },
      "source": [
        "### 2.2 Retrieve data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1D002WIVo_o",
        "outputId": "c996273c-0d00-407d-d30e-36e471d84975"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['userId', 'id', 'rating', 'timestamp', 'adult', 'belongs_to_collection',\n",
              "       'budget', 'genres', 'homepage', 'imdb_id', 'original_language',\n",
              "       'original_title', 'overview', 'popularity', 'poster_path',\n",
              "       'production_companies', 'production_countries', 'release_date',\n",
              "       'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title',\n",
              "       'video', 'vote_average', 'vote_count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "type(data)\n",
        "data.sample(5)\n",
        "data.columns\n",
        "#data.head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8__jFtAGSMIB"
      },
      "source": [
        "### 2.3 Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmZCTzdvSMIB"
      },
      "source": [
        "Before fitting the LightFM model, we need to create an instance of `Dataset` which holds the interaction matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "42Ax79LuSMIB"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7DinOuphiGer"
      },
      "outputs": [],
      "source": [
        "data.rename(columns = {'id':'itemID','userId':'userID' }, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dbXmicuSMIC"
      },
      "source": [
        "The `fit` method creates the user/item id mappings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8uGWGhbSMIC",
        "outputId": "d2985aae-078b-406b-909e-559a32f12895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num users: 671, num_topics: 2830.\n"
          ]
        }
      ],
      "source": [
        "dataset.fit(users=data['userID'], \n",
        "            items=data['itemID'])\n",
        "\n",
        "# quick check to determine the number of unique users and items in the data\n",
        "num_users, num_topics = dataset.interactions_shape()\n",
        "print(f'Num users: {num_users}, num_topics: {num_topics}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsWM5dReSMIC"
      },
      "source": [
        "Next is to build the interaction matrix. The `build_interactions` method returns 2 COO sparse matrices, namely the `interactions` and `weights` matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7d_jFt3nSMID"
      },
      "outputs": [],
      "source": [
        "(interactions, weights) = dataset.build_interactions(data.iloc[:, 0:3].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUvPo2GSMID"
      },
      "source": [
        "LightLM works slightly differently compared to other packages as it expects the train and test sets to have same dimension. Therefore the conventional train test split will not work.\n",
        "\n",
        "The package has included the `cross_validation.random_train_test_split` method to split the interaction data and splits it into two disjoint training and test sets. \n",
        "\n",
        "However, note that **it does not validate the interactions in the test set to guarantee all items and users have historical interactions in the training set**. Therefore this may result into a partial cold-start problem in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FKtlNi6KSMID"
      },
      "outputs": [],
      "source": [
        "train_interactions, test_interactions = cross_validation.random_train_test_split(\n",
        "    interactions, test_percentage=TEST_PERCENTAGE,\n",
        "    random_state=np.random.RandomState(SEEDNO))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G_J9iijSMID"
      },
      "source": [
        "Double check the size of both the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iftAdBsESMIE",
        "outputId": "cf487921-43e2-4c0c-dd2e-0fa44fca39f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train interactions: (671, 2830)\n",
            "Shape of test interactions: (671, 2830)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of train interactions: {train_interactions.shape}\")\n",
        "print(f\"Shape of test interactions: {test_interactions.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJCphzoDSMIE"
      },
      "source": [
        "### 2.4 Fit the LightFM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opoGBWn7SMIE"
      },
      "source": [
        "In this notebook, the LightFM model will be using the weighted Approximate-Rank Pairwise (WARP) as the loss. Further explanation on the topic can be found [here](https://making.lyst.com/lightfm/docs/examples/warp_loss.html#learning-to-rank-using-the-warp-loss).\n",
        "\n",
        "\n",
        "In general, it maximises the rank of positive examples by repeatedly sampling negative examples until a rank violation has been located. This approach is recommended when only positive interactions are present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WX5Td_jqSMIE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model1 = LightFM(loss='warp', no_components=NO_COMPONENTS, \n",
        "                 learning_rate=LEARNING_RATE,                 \n",
        "                 random_state=np.random.RandomState(SEEDNO))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGALH1oqSMIE"
      },
      "source": [
        "The LightFM model can be fitted with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_9UCz7VaSMIF"
      },
      "outputs": [],
      "source": [
        "model1.fit(interactions=train_interactions,\n",
        "          epochs=NO_EPOCHS);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqWRi-LVSMIF"
      },
      "source": [
        "### 2.5 Prepare model evaluation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcn3UgQ_SMIF"
      },
      "source": [
        "Before we can evaluate the fitted model and to get the data into a format which is compatible with the existing evaluation methods within this repo, the data needs to be massaged slightly.\n",
        "\n",
        "First the train/test indices need to be extracted from the `lightfm.cross_validation` method as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jeeF9uRFSMIF"
      },
      "outputs": [],
      "source": [
        "uids, iids, interaction_data = cross_validation._shuffle(\n",
        "    interactions.row, interactions.col, interactions.data, \n",
        "    random_state=np.random.RandomState(SEEDNO))\n",
        "\n",
        "cutoff = int((1.0 - TEST_PERCENTAGE) * len(uids))\n",
        "test_idx = slice(cutoff, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULzI3GYlSMIF"
      },
      "source": [
        "Then the the mapping between internal and external representation of the user and item are extracted as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uoNILmLtSMIG"
      },
      "outputs": [],
      "source": [
        "uid_map, ufeature_map, iid_map, ifeature_map = dataset.mapping()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkKbr1dKSMIG"
      },
      "source": [
        "Once the train/test indices and mapping are ready, the test dataframe can be constructed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7UnpjKmSMIG",
        "outputId": "010998a9-7d4e-4312-9843-77779502a0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Took 0.7 seconds for prepare and predict test data.\n"
          ]
        }
      ],
      "source": [
        "with Timer() as test_time:\n",
        "    test_df = prepare_test_df(test_idx, uids, iids, uid_map, iid_map, weights)\n",
        "print(f\"Took {test_time.interval:.1f} seconds for prepare and predict test data.\")  \n",
        "time_reco1 = test_time.interval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSVbNTJESMIG"
      },
      "source": [
        "And samples of the test dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yh3Tq022SMIG",
        "outputId": "70aa659c-22cc-49d9-95d4-bb2eabb17550"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      userID  itemID  rating\n",
              "1465     363     948     4.0\n",
              "1717     110     339     5.0\n",
              "9682     614     910     5.0\n",
              "594      481     318     3.5\n",
              "9855     564    3418     5.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d466f57c-0b12-43de-a772-28a488814afe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>363</td>\n",
              "      <td>948</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1717</th>\n",
              "      <td>110</td>\n",
              "      <td>339</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9682</th>\n",
              "      <td>614</td>\n",
              "      <td>910</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>481</td>\n",
              "      <td>318</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9855</th>\n",
              "      <td>564</td>\n",
              "      <td>3418</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d466f57c-0b12-43de-a772-28a488814afe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d466f57c-0b12-43de-a772-28a488814afe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d466f57c-0b12-43de-a772-28a488814afe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmpkehh4SMIG"
      },
      "source": [
        "In addition, the predictions of all unseen user-item pairs (e.g. removing those seen in the training data) can be prepared as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "H3f6ZAxwSMIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "f1066f3f-18c4-403f-bd89-817b39741504"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-df8ce31968ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                               \u001b[0minteractions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_interactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                               \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                               num_threads=NO_THREADS)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Took {test_time.interval:.1f} seconds for prepare and predict all data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtime_reco2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/recommenders/models/lightfm/lightfm_utils.py\u001b[0m in \u001b[0;36mprepare_all_predictions\u001b[0;34m(data, uid_map, iid_map, interactions, model, num_threads, user_features, item_features)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         )[0],\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/recommenders/models/lightfm/lightfm_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mitem_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mnum_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         )[0],\n\u001b[1;32m    267\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightfm/lightfm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, user_ids, item_ids, item_features, user_features, num_threads)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             raise TypeError(\n\u001b[0;32m--> 789\u001b[0;31m                 \u001b[0;34mf\"Invalid type passed to user_ids parameter. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0;34mf\"This must be either int or np.int32 array. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;34mf\"Type received: {type(user_ids)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid type passed to user_ids parameter. This must be either int or np.int32 array. Type received: <class 'numpy.int64'>"
          ]
        }
      ],
      "source": [
        "with Timer() as test_time:\n",
        "    all_predictions = prepare_all_predictions(data, uid_map, iid_map, \n",
        "                                              interactions=train_interactions,\n",
        "                                              model=model1, \n",
        "                                              num_threads=NO_THREADS)\n",
        "print(f\"Took {test_time.interval:.1f} seconds for prepare and predict all data.\")\n",
        "time_reco2 = test_time.interval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LElGmt1FSMIH"
      },
      "source": [
        "Samples of the `all_predictions` dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ3AOh5tSMIH"
      },
      "outputs": [],
      "source": [
        "all_predictions.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dafBmSLSMIH"
      },
      "source": [
        "Note that the **raw prediction values from the LightFM model are for ranking purposes only**, they should not be used directly. The magnitude and sign of these values do not have any specific interpretation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3vzHKzBSMIH"
      },
      "source": [
        "### 2.6 Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTuV_zBKSMII"
      },
      "source": [
        "Once the evaluation data are ready, they can be passed into to the repo's evaluation methods as follows. The performance of the model will be tracked using both Precision@K and Recall@K.\n",
        "\n",
        "In addition, the results have also being compared with those computed from LightFM's own evaluation methods to ensure accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmtQV3hhSMII"
      },
      "outputs": [],
      "source": [
        "with Timer() as test_time:\n",
        "    eval_precision = precision_at_k(rating_true=test_df, \n",
        "                                rating_pred=all_predictions, k=K)\n",
        "    eval_recall = recall_at_k(test_df, all_predictions, k=K)\n",
        "time_reco3 = test_time.interval\n",
        "\n",
        "with Timer() as test_time:\n",
        "    eval_precision_lfm = lightfm_prec_at_k(model1, test_interactions, \n",
        "                                           train_interactions, k=K).mean()\n",
        "    eval_recall_lfm = lightfm_recall_at_k(model1, test_interactions, \n",
        "                                          train_interactions, k=K).mean()\n",
        "time_lfm = test_time.interval\n",
        "    \n",
        "print(\n",
        "    \"------ Using Repo's evaluation methods ------\",\n",
        "    f\"Precision@K:\\t{eval_precision:.6f}\",\n",
        "    f\"Recall@K:\\t{eval_recall:.6f}\",\n",
        "    \"\\n------ Using LightFM evaluation methods ------\",\n",
        "    f\"Precision@K:\\t{eval_precision_lfm:.6f}\",\n",
        "    f\"Recall@K:\\t{eval_recall_lfm:.6f}\", \n",
        "    sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw6GOkSASMII"
      },
      "source": [
        "## 3. Movie recommender with LightFM using explicit feedbacks and additional item and user features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_V2UKUySMII"
      },
      "source": [
        "As the LightFM was designed to incorporates both user and item metadata, the model can be extended to include additional features such as movie genres and user occupations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67dPAe7USMII"
      },
      "source": [
        "### 3.1 Extract and prepare movie genres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdeh5lWPSMII"
      },
      "source": [
        "In this notebook, the movie's genres will be used as the item metadata. As the genres have already been loaded during the initial data import, it can be processed directly as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-AlDtfNSMII"
      },
      "outputs": [],
      "source": [
        "# split the genre based on the separator\n",
        "movie_genre = [x.split('|') for x in data['genre']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shbVBnPkSMIJ"
      },
      "outputs": [],
      "source": [
        "# retrieve the all the unique genres in the data\n",
        "all_movie_genre = sorted(list(set(itertools.chain.from_iterable(movie_genre))))\n",
        "# quick look at the all the genres within the data\n",
        "all_movie_genre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB5X_-avSMIJ"
      },
      "source": [
        "### 3.2 Retrieve and prepare movie genres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNTtKTRJSMIJ"
      },
      "source": [
        "Further user features can be included as part of the model fitting process. In this notebook, **only the occupation of each user will be included** but the feature list can be extended easily.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWLC9smtSMIJ"
      },
      "source": [
        "#### 3.2.1 Retrieve and merge data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-RNLG-BSMIJ"
      },
      "source": [
        "The user features can be retrieved directly from the grouplens website and merged with the existing data as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag2aHwyDSMIJ"
      },
      "outputs": [],
      "source": [
        "user_feature_URL = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.user'\n",
        "user_data = pd.read_table(user_feature_URL, \n",
        "              sep='|', header=None)\n",
        "user_data.columns = ['userID','age','gender','occupation','zipcode']\n",
        "\n",
        "# merging user feature with existing data\n",
        "new_data = data.merge(user_data[['userID','occupation']], left_on='userID', right_on='userID')\n",
        "# quick look at the merged data\n",
        "new_data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3OuQu-jSMIK"
      },
      "source": [
        "#### 3.2.2 Extract and prepare user occupations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UguNvaMBSMIK"
      },
      "outputs": [],
      "source": [
        "# retrieve all the unique occupations in the data\n",
        "all_occupations = sorted(list(set(new_data['occupation'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nBvjhVhSMIK"
      },
      "source": [
        "### 3.3 Prepare data and features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8emXlnESMIK"
      },
      "source": [
        "Similar to the previous model, the data is required to be converted into a `Dataset` instance and then create a user/item id mapping with the `fit` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4RGOZZ-SMIK"
      },
      "outputs": [],
      "source": [
        "dataset2 = Dataset()\n",
        "dataset2.fit(data['userID'], \n",
        "            data['itemID'], \n",
        "            item_features=all_movie_genre,\n",
        "            user_features=all_occupations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnBK5AH0SMIK"
      },
      "source": [
        "The movie genres are then converted into a item feature matrix using the `build_item_features` method as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtPgXyuWSMIL"
      },
      "outputs": [],
      "source": [
        "item_features = dataset2.build_item_features(\n",
        "    (x, y) for x,y in zip(data.itemID, movie_genre))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVT6ibtdSMIL"
      },
      "source": [
        "The user occupations are then converted into an user feature matrix using the `build_user_features` method as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk6Zqlq8SMIL"
      },
      "outputs": [],
      "source": [
        "user_features = dataset2.build_user_features(\n",
        "    (x, [y]) for x,y in zip(new_data.userID, new_data['occupation']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oybtj406SMIL"
      },
      "source": [
        "Once the item and user features matrices have been completed, the next steps are similar as before, which is to build the interaction matrix and split the interactions into train and test sets as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQScppfaSMIL"
      },
      "outputs": [],
      "source": [
        "(interactions2, weights2) = dataset2.build_interactions(data.iloc[:, 0:3].values)\n",
        "\n",
        "train_interactions2, test_interactions2 = cross_validation.random_train_test_split(\n",
        "    interactions2, test_percentage=TEST_PERCENTAGE,\n",
        "    random_state=np.random.RandomState(SEEDNO))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk5fBVNlSMIL"
      },
      "source": [
        "### 3.3 Fit the LightFM model with additional user and item features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ak__MHzSMIL"
      },
      "source": [
        "The parameters of the second model will be similar to the first model to facilitates comparison.\n",
        "\n",
        "The model performance at each epoch is also tracked by the same metrics as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ExZW5c5SMIM"
      },
      "outputs": [],
      "source": [
        "model2 = LightFM(loss='warp', no_components=NO_COMPONENTS, \n",
        "                 learning_rate=LEARNING_RATE, \n",
        "                 item_alpha=ITEM_ALPHA,\n",
        "                 user_alpha=USER_ALPHA,\n",
        "                 random_state=np.random.RandomState(SEEDNO))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yqwnZCUSMIM"
      },
      "source": [
        "The LightFM model can then be fitted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2jsftp8SMIM"
      },
      "outputs": [],
      "source": [
        "model2.fit(interactions=train_interactions2,\n",
        "           user_features=user_features,\n",
        "           item_features=item_features,\n",
        "           epochs=NO_EPOCHS);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlDPQXr0SMIM"
      },
      "source": [
        "### 3.4 Prepare model evaluation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v21OpmVPSMIM"
      },
      "source": [
        "Similar to the previous model, the evaluation data needs to be prepared in order to get them into a format consumable with this repo's evaluation methods.\n",
        "\n",
        "Firstly the train/test indices and id mappings are extracted using the new interations matrix as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF3nmAmHSMIM"
      },
      "outputs": [],
      "source": [
        "uids, iids, interaction_data = cross_validation._shuffle(\n",
        "    interactions2.row, interactions2.col, interactions2.data, \n",
        "    random_state=np.random.RandomState(SEEDNO))\n",
        "\n",
        "uid_map, ufeature_map, iid_map, ifeature_map = dataset2.mapping()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzartKYdSMIM"
      },
      "source": [
        "The test dataframe is then constructed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f30y8ES2SMIM"
      },
      "outputs": [],
      "source": [
        "with Timer() as test_time:\n",
        "    test_df2 = prepare_test_df(test_idx, uids, iids, uid_map, iid_map, weights2)\n",
        "print(f\"Took {test_time.interval:.1f} seconds for prepare and predict test data.\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrQ8S-7uSMIN"
      },
      "source": [
        "The predictions of all unseen user-item pairs can be prepared as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzZ-KARjSMIN"
      },
      "outputs": [],
      "source": [
        "with Timer() as test_time:\n",
        "    all_predictions2 = prepare_all_predictions(data, uid_map, iid_map, \n",
        "                                              interactions=train_interactions2,\n",
        "                                               user_features=user_features,\n",
        "                                               item_features=item_features,\n",
        "                                               model=model2,\n",
        "                                               num_threads=NO_THREADS)\n",
        "\n",
        "print(f\"Took {test_time.interval:.1f} seconds for prepare and predict all data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOS3FimWSMIN"
      },
      "source": [
        "### 3.5 Model evaluation and comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8clN24fSMIN"
      },
      "source": [
        "The predictive performance of the new model can be computed and compared with the previous model (which used only the explicit rating) as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JJmU6ptSMIN"
      },
      "outputs": [],
      "source": [
        "eval_precision2 = precision_at_k(rating_true=test_df2, \n",
        "                                rating_pred=all_predictions2, k=K)\n",
        "eval_recall2 = recall_at_k(test_df2, all_predictions2, k=K)\n",
        "\n",
        "print(\n",
        "    \"------ Using only explicit ratings ------\",\n",
        "    f\"Precision@K:\\t{eval_precision:.6f}\",\n",
        "    f\"Recall@K:\\t{eval_recall:.6f}\",\n",
        "    \"\\n------ Using both implicit and explicit ratings ------\",\n",
        "    f\"Precision@K:\\t{eval_precision2:.6f}\",\n",
        "    f\"Recall@K:\\t{eval_recall2:.6f}\",\n",
        "    sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1fXoa4nSMIN"
      },
      "source": [
        "The new model which used both implicit and explicit data performed consistently better than the previous model which used only the explicit data, thus highlighting the benefits of including such additional features to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnp_mdrvSMIN"
      },
      "source": [
        "### 3.6 Evaluation metrics comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x70aFo9DSMIO"
      },
      "source": [
        "Note that the evaluation approaches here are solely for demonstration purposes only.\n",
        "\n",
        "If the reader were using the LightFM package and/or its models, the LightFM's built-in evaluation methods are much more efficient and are the recommended approach for production usage as they are designed and optimised to work with the package.\n",
        "\n",
        "As a comparison, the times recorded to compute Precision@K and Recall@K for model1 are shown as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7V_4XdLSMIO"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"------ Using Repo's evaluation methods ------\",\n",
        "    f\"Time [sec]:\\t{(time_reco1+time_reco2+time_reco3):.1f}\",\n",
        "    \"\\n------ Using LightFM evaluation methods ------\",\n",
        "    f\"Time [sec]:\\t{time_lfm:.1f}\",\n",
        "    sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2gJi9xcSMIO"
      },
      "source": [
        "## 4. Evaluate model fitting process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3yVrwqcSMIO"
      },
      "source": [
        "In addition to the inclusion of both implicit and explicit data, the model fitting process can also be monitored in order to determine whether the model is being trained properly. \n",
        "\n",
        "This notebook also includes a `track_model_metrics` method which plots the model's metrics e.g. Precision@K and Recall@K as model fitting progresses.\n",
        "\n",
        "For the first model (using only explicit data), the model fitting progress is shown as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QeSN742SMIO"
      },
      "outputs": [],
      "source": [
        "output1, _ = track_model_metrics(model=model1, train_interactions=train_interactions, \n",
        "                              test_interactions=test_interactions, k=K,\n",
        "                              no_epochs=NO_EPOCHS, no_threads=NO_THREADS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igkSk10ESMIO"
      },
      "source": [
        "The second model (with both implicit and explicit data) fitting progress:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-dtT4NmSMIO"
      },
      "outputs": [],
      "source": [
        "output2, _ = track_model_metrics(model=model2, train_interactions=train_interactions2, \n",
        "                              test_interactions=test_interactions2, k=K,\n",
        "                              no_epochs=NO_EPOCHS, no_threads=NO_THREADS, \n",
        "                              item_features=item_features,\n",
        "                              user_features=user_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfSjfuvTSMIP"
      },
      "source": [
        "These show slightly different behaviour with the two approaches, the reader can then tune the hyperparameters to improve the model fitting process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D3_Km1jSMIP"
      },
      "source": [
        "### 4.1 Performance comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lLN02EzSMIP"
      },
      "source": [
        "In addition, the model's performance metrics (based on the test dataset) can be plotted together to facilitate easier comparison as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiZRpMzhSMIP"
      },
      "outputs": [],
      "source": [
        "for i in ['Precision', 'Recall']:\n",
        "    sns.set_palette(\"Set2\")\n",
        "    plt.figure()\n",
        "    sns.scatterplot(x=\"epoch\", y=\"value\", hue='data',\n",
        "                data=compare_metric(df_list = [output1, output2], metric=i)\n",
        "               ).set_title(f'{i} comparison using test set');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v25W-qCrSMIP"
      },
      "source": [
        "Referring to the figures above, it is rather obvious that the number of epochs is too low as the model's performances have not stabilised. Reader can decide on the number of epochs and other hyperparameters to adjust suit the application.\n",
        "\n",
        "As stated previously, it is interesting to see model2 (using both implicit and explicit data) performed consistently better than model1 (using only explicit ratings). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI6Os8qBSMIP"
      },
      "source": [
        "## 5. Similar users and items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnoVpHXkSMIP"
      },
      "source": [
        "As the LightFM package operates based on latent embeddings, these can be retrieved once the model has been fitted to assess user-user and/or item-item affinity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcDxCYF4SMIP"
      },
      "source": [
        "### 5.1 User affinity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp-vf63ASMIQ"
      },
      "source": [
        "The user-user affinity can be retrieved with the `get_user_representations` method from the fitted model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nB-LnK5SMIQ"
      },
      "outputs": [],
      "source": [
        "_, user_embeddings = model2.get_user_representations(features=user_features)\n",
        "user_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgXTvBPiSMIQ"
      },
      "source": [
        "In order to retrieve the top N similar users, we can use the `similar_users` from `recommenders`. For example, if we want to choose top 10 users most similar to the user 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxUHm-XQSMIQ"
      },
      "outputs": [],
      "source": [
        "similar_users(user_id=1, user_features=user_features, \n",
        "            model=model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk8wy6vFSMIQ"
      },
      "source": [
        "### 5.2 Item affinity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS8Mc0mTSMIQ"
      },
      "source": [
        "Similar to the user affinity, the item-item affinity can be retrieved with the `get_item_representations` method using the fitted model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd35GKoGSMIQ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "_, item_embeddings = model2.get_item_representations(features=item_features)\n",
        "item_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT3-2NyTSMIQ"
      },
      "source": [
        "The function to retrieve the top N similar items is similar to similar_users() above. For example, if we want to choose top 10 items most similar to the item 10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vRgcBnfSMIR"
      },
      "outputs": [],
      "source": [
        "similar_items(item_id=10, item_features=item_features, \n",
        "            model=model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__7vzmTxSMIR"
      },
      "source": [
        "## 6. Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B70C9C8_SMIR"
      },
      "source": [
        "In this notebook, the background of hybrid matrix factorisation model has been explained together with a detailed example of LightFM's implementation. \n",
        "\n",
        "The process of incorporating additional user and item metadata has also been demonstrated with performance comparison. Furthermore, the calculation of both user and item affinity scores have also been demonstrated and extracted from the fitted model.\n",
        "\n",
        "This notebook remains a fairly simple treatment on the subject and hopefully could serve as a good foundation for the reader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnEc_NRuSMIR"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cpR5NQiSMIR"
      },
      "source": [
        "- [[1](https://arxiv.org/abs/1507.08439)]. Maciej Kula - Metadata Embeddings for User and Item Cold-start Recommendations, 2015. arXiv:1507.08439\n",
        "- [[2](https://making.lyst.com/lightfm/docs/home.html)]. LightFM documentation,\n",
        "- [3]. Charu C. Aggarwal - Recommender Systems: The Textbook, Springer, April 2016. ISBN 978-3-319-29659-3\n",
        "- [4]. Deepak K. Agarwal, Bee-Chung Chen - Statistical Methods for Recommender Systems, 2016. ISBN: 9781107036079 \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jk8EXr8HSMIA",
        "8__jFtAGSMIB",
        "AJCphzoDSMIE",
        "a3vzHKzBSMIH",
        "67dPAe7USMII",
        "QB5X_-avSMIJ",
        "KWLC9smtSMIJ",
        "M3OuQu-jSMIK",
        "3nBvjhVhSMIK",
        "qk5fBVNlSMIL",
        "tlDPQXr0SMIM",
        "IOS3FimWSMIN",
        "Cnp_mdrvSMIN",
        "_D3_Km1jSMIP",
        "EcDxCYF4SMIP",
        "kk8wy6vFSMIQ"
      ],
      "machine_shape": "hm",
      "name": "2022apr22. ms.lightfm_deep_dive.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}